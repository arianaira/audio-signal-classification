# Heartbeat Sound Classification using CNN-RNN Models

## Project Overview

This project focuses on the classification of heartbeat audio signals from the Pascal Heart Sound Dataset. The primary goal is to build and evaluate a series of hybrid **CNN-RNN models** to accurately categorize recordings into one of five classes: `Normal`, `Murmur`, `Extra Heart Sound`, `Artifact`, and `Extrasystole`. The project implements various RNN architectures, including **LSTM**, **Bi-LSTM**, **GRU**, and **xLSTM**, to compare their effectiveness in processing sequential audio features.

---

## Methodology Pipeline

The project follows a systematic approach from data preparation to model evaluation.

### 1. Data Loading and Cleaning
- **Dataset Merging:** The two provided metadata files, `set_a.csv` and `set_b.csv`, were loaded.
- **Path Correction:** The file paths in `set_b.csv` were found to be incorrect. The dataframe was regenerated by scanning the audio directory and extracting labels directly from the filenames.
- **Handling Missing Values:** Samples with missing labels were dropped to ensure data quality, resulting in a clean dataset of 637 audio samples.

### 2. Audio Preprocessing
To ensure consistency across all input samples, a standardized audio length was enforced:
- All audio files were processed to a uniform duration of **5 seconds**.
- Longer files were truncated, and shorter files were padded with silence.

### 3. Feature Extraction
- **MFCCs (Mel-Frequency Cepstral Coefficients)** were chosen as the feature extraction method. This technique converts the raw audio waveforms into a spectral representation that captures the phonetic and auditory characteristics of the sound, making it suitable for machine learning models.

### 4. Model Architecture
A hybrid CNN-RNN architecture was designed to leverage the strengths of both model types:
- **CNN Backbone (Feature Extractor):** A Convolutional Neural Network processes the 2D MFCC feature maps to extract relevant spatial patterns. The project tested two CNN backbones:
    1. A simple, custom-built CNN with two convolutional layers.
    2. A pre-trained **ResNet18** model for more powerful feature extraction.
- **RNN Backend (Sequence Processor):** The sequence of features extracted by the CNN is then fed into a Recurrent Neural Network to model temporal dependencies in the audio signal.

### 5. Model Variants Tested
To find the most effective architecture for capturing long-term dependencies, the simple RNN layer was replaced with several advanced variants:
- **Simple RNN** (Baseline)
- **LSTM** (Long Short-Term Memory)
- **Bi-LSTM** (Bidirectional LSTM)
- **GRU** (Gated Recurrent Unit)
- **xLSTM** (Extended Long Short-Term Memory)

---

## Results and Performance

Each model variant was trained for 100 epochs (or 10 epochs for the computationally expensive ResNet-based models) and evaluated on the test set. The key performance metrics are summarized below.

| Model Variant         | Test Accuracy | Precision (Micro) | Recall (Micro) |
| --------------------- | :-----------: | :---------------: | :------------: |
| **Simple RNN** |   **88.7%** |     **73.8%** |   **67.5%** |
| **LSTM** |     88.7%     |       72.0%       |     67.5%      |
| **GRU** |     86.9%     |       69.3%       |     64.0%      |
| **Bi-LSTM** |     86.5%     |       68.6%       |     63.2%      |
| **xLSTM** |     83.7%     |       61.5%       |     55.9%      |
| **ResNet18 + RNN** |   **88.7%** |     **73.1%** |   **68.4%** |
| **ResNet18 + LSTM** |     87.3%     |       69.1%       |     67.5%      |

---

## Conclusion

The results demonstrate the effectiveness of the hybrid CNN-RNN approach for heartbeat sound classification.

- The **Simple RNN** and **LSTM** models achieved the highest performance, with a test accuracy of approximately **88.7%**, successfully exceeding the 80% target accuracy.
- Using a pre-trained **ResNet18** as the CNN feature extractor provided a significant performance boost, especially for the Simple RNN model, even with fewer training epochs.
- The more complex models like Bi-LSTM and xLSTM did not outperform the simpler variants on this dataset, suggesting that a well-tuned LSTM or Simple RNN is sufficient for this task.
